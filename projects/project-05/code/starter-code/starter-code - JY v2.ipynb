{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import feature_extraction, feature_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from sklearn import grid_search\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/.anaconda/lib/python2.7/site-packages/IPython/config.py:13: ShimWarning: The `IPython.config` package has been deprecated. You should import from traitlets.config instead.\n",
      "  \"You should import from traitlets.config instead.\", ShimWarning)\n",
      "/home/vagrant/.anaconda/lib/python2.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Task: Describe the goals of your study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Aquire the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "#password: gastudents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Connect to the remote database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>table_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>account_information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>evictions_simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>howie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>jacques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>table1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>user</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(u'account',),\n",
       " (u'account_information',),\n",
       " (u'evictions_simple',),\n",
       " (u'howie',),\n",
       " (u'jacques',),\n",
       " (u'table1',),\n",
       " (u'train',),\n",
       " (u'user',)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic\n",
    "SELECT table_name\n",
    "FROM information_schema.tables\n",
    "where table_catalog = 'titanic'\n",
    "and table_schema = 'public'\n",
    "ORDER BY table_name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>index</th>\n",
       "        <th>PassengerId</th>\n",
       "        <th>Survived</th>\n",
       "        <th>Pclass</th>\n",
       "        <th>Name</th>\n",
       "        <th>Sex</th>\n",
       "        <th>Age</th>\n",
       "        <th>SibSp</th>\n",
       "        <th>Parch</th>\n",
       "        <th>Ticket</th>\n",
       "        <th>Fare</th>\n",
       "        <th>Cabin</th>\n",
       "        <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "        <td>1</td>\n",
       "        <td>0</td>\n",
       "        <td>3</td>\n",
       "        <td>Braund, Mr. Owen Harris</td>\n",
       "        <td>male</td>\n",
       "        <td>22.0</td>\n",
       "        <td>1</td>\n",
       "        <td>0</td>\n",
       "        <td>A/5 21171</td>\n",
       "        <td>7.25</td>\n",
       "        <td>None</td>\n",
       "        <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>2</td>\n",
       "        <td>1</td>\n",
       "        <td>1</td>\n",
       "        <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "        <td>female</td>\n",
       "        <td>38.0</td>\n",
       "        <td>1</td>\n",
       "        <td>0</td>\n",
       "        <td>PC 17599</td>\n",
       "        <td>71.2833</td>\n",
       "        <td>C85</td>\n",
       "        <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>3</td>\n",
       "        <td>1</td>\n",
       "        <td>3</td>\n",
       "        <td>Heikkinen, Miss. Laina</td>\n",
       "        <td>female</td>\n",
       "        <td>26.0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>STON/O2. 3101282</td>\n",
       "        <td>7.925</td>\n",
       "        <td>None</td>\n",
       "        <td>S</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0L, 1L, 0L, 3L, u'Braund, Mr. Owen Harris', u'male', 22.0, 1L, 0L, u'A/5 21171', 7.25, None, u'S'),\n",
       " (1L, 2L, 1L, 1L, u'Cumings, Mrs. John Bradley (Florence Briggs Thayer)', u'female', 38.0, 1L, 0L, u'PC 17599', 71.2833, u'C85', u'C'),\n",
       " (2L, 3L, 1L, 3L, u'Heikkinen, Miss. Laina', u'female', 26.0, 0L, 0L, u'STON/O2. 3101282', 7.925, None, u'S')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from train limit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Query the database and aggregate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 rows affected.\n"
     ]
    }
   ],
   "source": [
    "df = %sql select * from train;\n",
    "df = df.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Survived  Pclass  \\\n",
       "0      0            1         0       3   \n",
       "1      1            2         1       1   \n",
       "2      2            3         1       3   \n",
       "3      3            4         1       1   \n",
       "4      4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  None        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  None        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500  None        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are the risks and assumptions of our data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Describe the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "index          891 non-null int64\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeriesImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Impute missing values.\n",
    "       Columns of dtype object are imputed with the most frequent value \n",
    "       in column.\n",
    "\n",
    "       Columns of other types are imputed with mean of column.\n",
    "    \"\"\"\n",
    "       # def __init__(self)\n",
    "   \n",
    "    def fit(self, X, y=None):\n",
    "        if len(X.mode()) != 0 :\n",
    "            self.fill = (X.mode()[0] if X.dtype == np.dtype('O') else X.mean())\n",
    "        else :      \n",
    "            self.fill = X[X.first_valid_index()]        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DictVectSeries(BaseEstimator, TransformerMixin):\n",
    " \n",
    "\n",
    "    def fit(self, X, y=None):    \n",
    "      \n",
    "        X = X.astype(str)       \n",
    "        samples = [dict(enumerate(sample)) for sample in X]\n",
    "        \n",
    "        self.dict_ = DictVectorizer()      \n",
    "        self.dict_.fit(samples)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "      \n",
    "        X = X.astype(str)\n",
    "        samples = [dict(enumerate(sample)) for sample in X]      \n",
    "        return self.dict_.transform(samples)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SelectOneColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # return X.ix[:, self.column]\n",
    "        return X[self.column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GetVectorizeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self = self\n",
    "        \n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "       # if isinstance(X, pd.Series):\n",
    "        return feature_extraction.text.TfidfVectorizer().fit_transform(X)\n",
    "       # else:\n",
    "     #       raise TypeError(\"This transformer only works with Pandas Dataframes\")\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DFback(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # return X.ix[:, self.column]\n",
    "        return pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OneHotEncoderPandasCategoricalSeries() df['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Embarked_pipe = Pipeline([('Col_Embarked', SelectOneColumn('Embarked')), \n",
    "                          ('Fill_na_Embarked', SeriesImputer()),\n",
    "                        \n",
    "                        ('Dummy_Embarked', DictVectSeries())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SibSp_pipe = Pipeline([('Col_SibSp', SelectOneColumn('SibSp')), \n",
    "                       ('Fill_na_SibSp', SeriesImputer()),\n",
    "                      \n",
    "                      ('Dummy_SibSp', DictVectSeries())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Age_pipe = Pipeline([('Col_Age', SelectOneColumn('Age')), \n",
    "                      ('Fill_na_Age', SeriesImputer()),\n",
    "                     ('DataFrame_Age',DFback()),\n",
    "                      ('StandardScaler_Age', MinMaxScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Fare_pipe = Pipeline([('Col_Fare', SelectOneColumn('Fare')), \n",
    "                      ('Fill_na_Fare', SeriesImputer()),\n",
    "                      ('DataFrame_Age',DFback()),\n",
    "                      ('StandardScaler_Fare', MinMaxScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testpipe = Pipeline([('test', CatOneColumn())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Embarked_pipe = Pipeline([('Col_Embarked', SelectOneColumn('Embarked')), \n",
    "                          ('Fill_na_Embarked', SeriesImputer()),\n",
    "                        ('Dummy_Embarked', DictVectSeries())])\n",
    "Sex_pipe = Pipeline([('Col_Sex', SelectOneColumn('Sex')), \n",
    "                      ('Fill_na_Sex', SeriesImputer()),\n",
    "                       ('Dummy_Sex', DictVectSeries())])\n",
    "Pclass_pipe = Pipeline([('Col_Pclass', SelectOneColumn('Pclass')), \n",
    "                        ('Fill_na_Pclass', SeriesImputer()),\n",
    "                      ('Dummy_Pclass', DictVectSeries())])\n",
    "SibSp_pipe = Pipeline([('Col_SibSp', SelectOneColumn('SibSp')), \n",
    "                       ('Fill_na_SibSp', SeriesImputer()),\n",
    "                      ('Dummy_SibSp', DictVectSeries())])\n",
    "Parch_pipe = Pipeline([('Col_Parch', SelectOneColumn('Parch')), \n",
    "                       ('Fill_na_Parch', SeriesImputer()),\n",
    "                      ('Dummy_Parch', DictVectSeries())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Name_pipe = Pipeline([('Col_Name', SelectOneColumn('Name')), \n",
    "                       ('Fill_na_Name', SeriesImputer()),\n",
    "                      ('Vectorize_Name', TfidfVectorizer()),\n",
    "                         ('Dense_Name', DenseTransformer())])\n",
    "Ticket_pipe = Pipeline([('Col_Ticket', SelectOneColumn('Ticket')), \n",
    "                       ('Fill_na_Ticket', SeriesImputer()),\n",
    "                      ('Vectorize_Ticket', TfidfVectorizer()),\n",
    "                         ('Dense_Ticket', DenseTransformer())])\n",
    "Cabin_pipe = Pipeline([('Col_Cabin', SelectOneColumn('Cabin')), \n",
    "                       ('Fill_na_Cabin', SeriesImputer()),\n",
    "                      ('Vectorize_Cabin', TfidfVectorizer()),\n",
    "                         ('Dense_Cabin', DenseTransformer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "union = make_union(Age_pipe, Fare_pipe, \n",
    "                   Embarked_pipe, Sex_pipe, Pclass_pipe, SibSp_pipe, Parch_pipe, \n",
    "                   Name_pipe,Ticket_pipe, Cabin_pipe\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df #[list(set(df.columns)-set(['Cabin']))]\n",
    "y = df[u'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#union.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = cross_validation.KFold(len(y), n_folds=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = cross_validation.cross_val_score(LogisticRegression(), \n",
    "                                          X=union.fit_transform(X), y=y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82681564,  0.83146067,  0.82022472,  0.82022472,  0.79213483])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81817211725566508"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, use feature_selection first and then LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "union_pipe = make_pipeline(union, feature_selection.SelectFromModel(LogisticRegressionCV()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = cross_validation.cross_val_score(LogisticRegression(), \n",
    "                                          X=union_pipe.fit(X,y).transform(X), y=y, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82718598958006395"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xt = union_pipe.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_pipe = Pipeline([('Logistic_Reg', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Logistic_Reg__multi_class',\n",
       " 'Logistic_Reg__dual',\n",
       " 'Logistic_Reg__fit_intercept',\n",
       " 'Logistic_Reg__max_iter',\n",
       " 'Logistic_Reg__intercept_scaling',\n",
       " 'Logistic_Reg__warm_start',\n",
       " 'Logistic_Reg__penalty',\n",
       " 'Logistic_Reg__n_jobs',\n",
       " 'Logistic_Reg__C',\n",
       " 'Logistic_Reg__solver',\n",
       " 'steps',\n",
       " 'Logistic_Reg__class_weight',\n",
       " 'Logistic_Reg__random_state',\n",
       " 'Logistic_Reg__tol',\n",
       " 'Logistic_Reg',\n",
       " 'Logistic_Reg__verbose']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_parameters = {\n",
    "    'Logistic_Reg__penalty':['l1','l2'],\n",
    "    'Logistic_Reg__C':np.logspace(-5,1,50),\n",
    "    'Logistic_Reg__solver':['liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs = grid_search.GridSearchCV(grid_search_pipe, param_grid=logreg_parameters, cv=cv, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=891, n_folds=5, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('Logistic_Reg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'Logistic_Reg__solver': ['liblinear'], 'Logistic_Reg__penalty': ['l1', 'l2'], 'Logistic_Reg__C': array([  1.00000e-05,   1.32571e-05,   1.75751e-05,   2.32995e-05,\n",
       "         3.08884e-05,   4.09492e-05,   5.42868e-05,   7.19686e-05,\n",
       "         9.54095e-05,   1.26486e-04,   1.67683e-04,   2.2...    2.44205e+00,   3.23746e+00,   4.29193e+00,   5.68987e+00,\n",
       "         7.54312e+00,   1.00000e+01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(Xt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85185185185185186"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Logistic_Reg', LogisticRegression(C=2.4420530945486498, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic_Reg__C': 2.4420530945486498,\n",
       " 'Logistic_Reg__penalty': 'l2',\n",
       " 'Logistic_Reg__solver': 'liblinear'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_knn_pipe = Pipeline([('KNN', neighbors.KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KNN',\n",
       " 'KNN__p',\n",
       " 'KNN__metric',\n",
       " 'KNN__weights',\n",
       " 'KNN__leaf_size',\n",
       " 'KNN__algorithm',\n",
       " 'steps',\n",
       " 'KNN__n_neighbors',\n",
       " 'KNN__n_jobs',\n",
       " 'KNN__metric_params']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_knn_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_parameters = {\n",
    "    'KNN__n_neighbors':[3,5,7,9,15,21],\n",
    "    'KNN__p':[1,2],\n",
    "    'KNN__weights':['uniform', 'distance']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_knn = grid_search.GridSearchCV(grid_search_knn_pipe, param_grid=knn_parameters, cv=cv, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=891, n_folds=5, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'KNN__p': [1, 2], 'KNN__weights': ['uniform', 'distance'], 'KNN__n_neighbors': [3, 5, 7, 9, 15, 21]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.fit(Xt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77553310886644222"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=1,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN__n_neighbors': 3, 'KNN__p': 1, 'KNN__weights': 'uniform'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### worse than LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Visualize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create Dummy Variables for *Sex* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Logistic Regression and Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define the variables that we will use in our classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Transform \"Y\" into a 1-Dimensional Array for SciKit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Conduct the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Examine the coefficients to see our correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Test the Model by introducing a *Test* or *Validaton* set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Predict the class labels for the *Test* set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Predict the class probabilities for the *Test* set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Evaluate the *Test* set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Cross validate the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Check the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc\n",
    "\n",
    "def print_cm_cr(y_true, y_pred, names):\n",
    "    \"\"\"prints the confusion matrix and the classification report\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cols = ['pred_' + c for c in names]\n",
    "    dfcm = pd.DataFrame(cm, columns = cols, index = names)\n",
    "    print dfcm\n",
    "    print\n",
    "    print classification_report(y_true, y_pred, target_names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_cm_cr(X, y, names):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    fit_model = union_pipe.fit(X_train,y_train)\n",
    "    X_train_t = fit_model.transform(X_train)\n",
    "    \n",
    "    cv = cross_validation.KFold(len(y_train), n_folds=5, shuffle=True)\n",
    "    gs = grid_search.GridSearchCV(grid_search_pipe, param_grid=logreg_parameters, cv=cv, verbose=1, n_jobs=-1)\n",
    "    \n",
    "    gs.fit(X_train_t, y_train)\n",
    "    \n",
    "    X_test_t = fit_model.transform(X_test)\n",
    "    y_pred = gs.predict(X_test_t)\n",
    "    \n",
    "    print_cm_cr(y_test, y_pred, names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "          pred_dead  pred_survived\n",
      "dead            154             28\n",
      "survived         32             81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       dead       0.83      0.85      0.84       182\n",
      "   survived       0.74      0.72      0.73       113\n",
      "\n",
      "avg / total       0.80      0.80      0.80       295\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "do_cm_cr(X, y, ['dead', 'survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. What do the classification metrics tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision for predicting survived is worse than predicting dead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Check the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. What does the Confusion Matrix tell us? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-2b7b1507c5ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mFPR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mTPR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mROC_AUC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_t' is not defined"
     ]
    }
   ],
   "source": [
    "y_score = gs.decision_function(X_test_t)\n",
    "\n",
    "FPR = dict()\n",
    "TPR = dict()\n",
    "ROC_AUC = dict()\n",
    "\n",
    "# For class 1, find the area under the curve\n",
    "FPR[1], TPR[1], _ = roc_curve(y_test, y_score)\n",
    "ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "# Plot of a ROC curve for class 1 (has_cancer)\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver operating characteristic for survival detection', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_cm_cr_knn(X, y, names):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    fit_model = union_pipe.fit(X_train,y_train)\n",
    "    X_train_t = fit_model.transform(X_train)\n",
    "    \n",
    "    cv = cross_validation.KFold(len(y_train), n_folds=5, shuffle=True)\n",
    "    gs_knn = grid_search.GridSearchCV(grid_search_knn_pipe, param_grid=knn_parameters, cv=cv, verbose=1, n_jobs=-1)\n",
    "    \n",
    "    gs_knn.fit(X_train_t, y_train)\n",
    "    \n",
    "    X_test_t = fit_model.transform(X_test)\n",
    "    y_pred = gs_knn.predict(X_test_t)\n",
    "    \n",
    "    print_cm_cr(y_test, y_pred, names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "do_cm_cr_knn(X, y, ['dead', 'survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_log_score = gs.decision_function(X_test_t)\n",
    "y_knn_score = gs_knn.decision_function(X_test_t)\n",
    "\n",
    "score_list = [y_log_score,y_knn_score]\n",
    "names = ['Logistic','KNN']\n",
    "\n",
    "def plotROC(score_list, names):\n",
    "    FPR = dict()\n",
    "    TPR = dict()\n",
    "    ROC_AUC = dict()\n",
    "\n",
    "    plt.figure(figsize=[11,9])\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.title('Receiver operating characteristic for survival detection', fontsize=18)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    for i in range(len(score_list)):\n",
    "    \n",
    "        \n",
    "        FPR[1], TPR[1], _ = roc_curve(y_test, score_list[i])\n",
    "        ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "        \n",
    "\n",
    "        plt.plot(FPR[1], TPR[1], label='% ROC curve (area = %0.2f)' % (names[i],ROC_AUC[1]), linewidth=4)\n",
    "        \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plotROC(score_list, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mtest = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtest.decision_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc(models):\n",
    "\n",
    "    colors = ['b', 'g', 'y', 'm', 'r', 'k']\n",
    "  \n",
    "    for i, j in enumerate(models):\n",
    "        j.fit(X_train_t, y_train)\n",
    "        probs = j.predict_proba(X_test_t)\n",
    "        preds = probs[:,1]\n",
    "        fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, 'b', label = str(type(j))+' AUC = %0.2f' % roc_auc, color=colors[i])\n",
    "      \n",
    "    plt.title('Receiver Operating Characteristic')        \n",
    "    plt.legend(bbox_to_anchor=(2,1), loc='lower right', ncol=1)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_list = [gs,gs_knn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. What does the ROC curve tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use GridSearchCV with logistic regression to search for optimal parameters \n",
    "\n",
    "- Use the provided parameter grid. Feel free to add if you like (such as n_jobs).\n",
    "- Use 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print out the best parameters and best score. Are they better than the vanilla logistic regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explain the difference between the difference between the L1 (Lasso) and L2 (Ridge) penalties on the model coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What hypothetical situations are the Ridge and Lasso penalties useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. [BONUS] Explain how the regularization strength (C) modifies the regression loss function. Why do the Ridge and Lasso penalties have their respective effects on the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.a. [BONUS] You decide that you want to minimize false positives. Use the predicted probabilities from the model to set your threshold for labeling the positive class to need at least 90% confidence. How and why does this affect your confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Gridsearch and kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform Gridsearch for the same classification problem as above, but use KNeighborsClassifier as your estimator\n",
    "\n",
    "At least have number of neighbors and weights in your parameters dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print the best parameters and score for the gridsearched kNN model. How does it compare to the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. How does the number of neighbors affect the bias-variance tradeoff of your model?\n",
    "\n",
    "#### [BONUS] Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. In what hypothetical scenario(s) might you prefer logistic regression over kNN, aside from model performance metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Fit a new kNN model with the optimal parameters found in gridsearch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Construct the confusion matrix for the optimal kNN model. Is it different from the logistic regression model? If so, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. [BONUS] Plot the ROC curves for the optimized logistic regression model and the optimized kNN model on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: [BONUS] Precision-recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Gridsearch the same parameters for logistic regression but change the scoring function to 'average_precision'\n",
    "\n",
    "`'average_precision'` will optimize parameters for area under the precision-recall curve instead of for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Examine the best parameters and score. Are they different than the logistic regression gridsearch in part 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create the confusion matrix. Is it different than when you optimized for the accuracy? If so, why would this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Plot the precision-recall curve. What does this tell us as opposed to the ROC curve?\n",
    "\n",
    "[See the sklearn plotting example here.](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: [VERY BONUS] Decision trees, ensembles, bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Gridsearch a decision tree classifier model on the data, searching for optimal depth. Create a new decision tree model with the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compare the performace of the decision tree model to the logistic regression and kNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Plot all three optimized models' ROC curves on the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use sklearn's BaggingClassifier with the base estimator your optimized decision tree model. How does the performance compare to the single decision tree classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Gridsearch the optimal n_estimators, max_samples, and max_features for the bagging classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Create a bagging classifier model with the optimal parameters and compare it's performance to the other two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
