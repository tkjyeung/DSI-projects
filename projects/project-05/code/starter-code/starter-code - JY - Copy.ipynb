{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import feature_extraction, feature_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/.anaconda/lib/python2.7/site-packages/IPython/config.py:13: ShimWarning: The `IPython.config` package has been deprecated. You should import from traitlets.config instead.\n",
      "  \"You should import from traitlets.config instead.\", ShimWarning)\n",
      "/home/vagrant/.anaconda/lib/python2.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Task: Describe the goals of your study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Aquire the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "#password: gastudents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Connect to the remote database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>table_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>account_information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>evictions_simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>howie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>jacques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>table1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>user</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(u'account',),\n",
       " (u'account_information',),\n",
       " (u'evictions_simple',),\n",
       " (u'howie',),\n",
       " (u'jacques',),\n",
       " (u'table1',),\n",
       " (u'train',),\n",
       " (u'user',)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic\n",
    "SELECT table_name\n",
    "FROM information_schema.tables\n",
    "where table_catalog = 'titanic'\n",
    "and table_schema = 'public'\n",
    "ORDER BY table_name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>index</th>\n",
       "        <th>PassengerId</th>\n",
       "        <th>Survived</th>\n",
       "        <th>Pclass</th>\n",
       "        <th>Name</th>\n",
       "        <th>Sex</th>\n",
       "        <th>Age</th>\n",
       "        <th>SibSp</th>\n",
       "        <th>Parch</th>\n",
       "        <th>Ticket</th>\n",
       "        <th>Fare</th>\n",
       "        <th>Cabin</th>\n",
       "        <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "        <td>1</td>\n",
       "        <td>0</td>\n",
       "        <td>3</td>\n",
       "        <td>Braund, Mr. Owen Harris</td>\n",
       "        <td>male</td>\n",
       "        <td>22.0</td>\n",
       "        <td>1</td>\n",
       "        <td>0</td>\n",
       "        <td>A/5 21171</td>\n",
       "        <td>7.25</td>\n",
       "        <td>None</td>\n",
       "        <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>2</td>\n",
       "        <td>1</td>\n",
       "        <td>1</td>\n",
       "        <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "        <td>female</td>\n",
       "        <td>38.0</td>\n",
       "        <td>1</td>\n",
       "        <td>0</td>\n",
       "        <td>PC 17599</td>\n",
       "        <td>71.2833</td>\n",
       "        <td>C85</td>\n",
       "        <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>3</td>\n",
       "        <td>1</td>\n",
       "        <td>3</td>\n",
       "        <td>Heikkinen, Miss. Laina</td>\n",
       "        <td>female</td>\n",
       "        <td>26.0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>STON/O2. 3101282</td>\n",
       "        <td>7.925</td>\n",
       "        <td>None</td>\n",
       "        <td>S</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0L, 1L, 0L, 3L, u'Braund, Mr. Owen Harris', u'male', 22.0, 1L, 0L, u'A/5 21171', 7.25, None, u'S'),\n",
       " (1L, 2L, 1L, 1L, u'Cumings, Mrs. John Bradley (Florence Briggs Thayer)', u'female', 38.0, 1L, 0L, u'PC 17599', 71.2833, u'C85', u'C'),\n",
       " (2L, 3L, 1L, 3L, u'Heikkinen, Miss. Laina', u'female', 26.0, 0L, 0L, u'STON/O2. 3101282', 7.925, None, u'S')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from train limit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Query the database and aggregate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 rows affected.\n"
     ]
    }
   ],
   "source": [
    "df = %sql select * from train;\n",
    "df = df.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Survived  Pclass  \\\n",
       "0      0            1         0       3   \n",
       "1      1            2         1       1   \n",
       "2      2            3         1       3   \n",
       "3      3            4         1       1   \n",
       "4      4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  None        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  None        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500  None        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are the risks and assumptions of our data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Describe the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "index          891 non-null int64\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeriesImputer(TransformerMixin):\n",
    "    \"\"\" Impute missing values.\n",
    "       Columns of dtype object are imputed with the most frequent value \n",
    "       in column.\n",
    "\n",
    "       Columns of other types are imputed with mean of column.\n",
    "    \"\"\"\n",
    "   # def __init__(self)\n",
    "   \n",
    "    def fit(self, X, y=None):\n",
    "#value_counts().index[0]\n",
    "        if len(X.mode()) != 0 :\n",
    "            self.fill = (X.mode()[0] if X.dtype == np.dtype('O') else X.mean())\n",
    "        else :\n",
    "            self.fill = X[0]\n",
    "       # print self.fill\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OneHotEncoderPandasCategoricalSeries():\n",
    "    def __init__(self, sparse=False, **kwargs):\n",
    "      #  self = self.astype('category')\n",
    "        self.ohe = preprocessing.OneHotEncoder(handle_unknown='ignore', sparse=sparse, **kwargs)\n",
    "\n",
    "    def _X_for_onehotenc(self, X):\n",
    "        #X = X.astype('category')\n",
    "        return X.cat.codes.reshape(-1,1 )\n",
    "        # return [[x] for x in X.cat.codes]\n",
    "    \n",
    "    def fit(self, X, y=None):    \n",
    "      #  X = X.astype('category') ##\n",
    "        self.categories = X.cat.categories\n",
    "        self.ohe.fit(self._X_for_onehotenc(X))\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "   #     X = X.astype('category') ##\n",
    "        if np.all(X.cat.categories != self.categories):\n",
    "            X = pd.Categorical(X, categories=self.categories)\n",
    "        return self.ohe.transform(self._X_for_onehotenc(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CatOneColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, data_type='category'):\n",
    "        self.data_type = data_type #= self.astype(data_type)\n",
    "\n",
    "    def fit(self, X, y=None):        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # return X.ix[:, self.column]\n",
    "        return X.astype(self.data_type)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SelectOneColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # return X.ix[:, self.column]\n",
    "        return X[self.column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GetVectorizeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self = self\n",
    "        \n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "       # if isinstance(X, pd.Series):\n",
    "        return feature_extraction.text.TfidfVectorizer().fit_transform(X)\n",
    "       # else:\n",
    "     #       raise TypeError(\"This transformer only works with Pandas Dataframes\")\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DFback(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # return X.ix[:, self.column]\n",
    "        return pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UnionFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self = self\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # return X.ix[:, self.column]\n",
    "        return make_union(Age_pipe, Fare_pipe, \n",
    "                   Embarked_pipe, Sex_pipe, Pclass_pipe, SibSp_pipe, Parch_pipe, \n",
    "                   Name_pipe,Ticket_pipe, Cabin_pipe\n",
    "                  )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OneHotEncoderPandasCategoricalSeries() df['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Age_pipe = Pipeline([('Col_Age', SelectOneColumn('Age')), \n",
    "                      ('Fill_na_Age', SeriesImputer()),\n",
    "                     ('DataFrame_Age',DFback()),\n",
    "                      ('StandardScaler_Age', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Fare_pipe = Pipeline([('Col_Fare', SelectOneColumn('Fare')), \n",
    "                      ('Fill_na_Fare', SeriesImputer()),\n",
    "                      ('DataFrame_Age',DFback()),\n",
    "                      ('StandardScaler_Fare', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testpipe = Pipeline([('test', CatOneColumn())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Embarked_pipe = Pipeline([('Col_Embarked', SelectOneColumn('Embarked')), \n",
    "                          ('Fill_na_Embarked', SeriesImputer()),\n",
    "                          ('Cat_Embarked', CatOneColumn()),\n",
    "                        ('Dummy_Embarked', OneHotEncoderPandasCategoricalSeries())])\n",
    "Sex_pipe = Pipeline([('Col_Sex', SelectOneColumn('Sex')), \n",
    "                      ('Fill_na_Sex', SeriesImputer()),\n",
    "                      ('Cat_Sex', CatOneColumn()),\n",
    "                      ('Dummy_Sex', OneHotEncoderPandasCategoricalSeries())])\n",
    "Pclass_pipe = Pipeline([('Col_Pclass', SelectOneColumn('Pclass')), \n",
    "                        ('Fill_na_Pclass', SeriesImputer()),\n",
    "                        ('Cat_Pclass', CatOneColumn()),\n",
    "                      ('Dummy_Pclass', OneHotEncoderPandasCategoricalSeries())])\n",
    "SibSp_pipe = Pipeline([('Col_SibSp', SelectOneColumn('SibSp')), \n",
    "                       ('Fill_na_SibSp', SeriesImputer()),\n",
    "                       ('Cat_SibSp', CatOneColumn()),\n",
    "                      ('Dummy_SibSp', OneHotEncoderPandasCategoricalSeries())])\n",
    "Parch_pipe = Pipeline([('Col_Parch', SelectOneColumn('Parch')), \n",
    "                       ('Fill_na_Parch', SeriesImputer()),\n",
    "                       ('Cat_Parch', CatOneColumn()),\n",
    "                      ('Dummy_Parch', OneHotEncoderPandasCategoricalSeries())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Name_pipe = Pipeline([('Col_Name', SelectOneColumn('Name')), \n",
    "                       ('Fill_na_Name', SeriesImputer()),\n",
    "                      ('Vectorize_Name', TfidfVectorizer())])\n",
    "Ticket_pipe = Pipeline([('Col_Ticket', SelectOneColumn('Ticket')), \n",
    "                       ('Fill_na_Ticket', SeriesImputer()),\n",
    "                      ('Vectorize_Ticket', TfidfVectorizer())])\n",
    "Cabin_pipe = Pipeline([('Col_Cabin', SelectOneColumn('Cabin')), \n",
    "                       ('Fill_na_Cabin', SeriesImputer()),\n",
    "                      ('Vectorize_Cabin', TfidfVectorizer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "union = make_union(Age_pipe, Fare_pipe, \n",
    "                   Embarked_pipe, Sex_pipe, Pclass_pipe, SibSp_pipe, Parch_pipe, \n",
    "                   Name_pipe,Ticket_pipe, Cabin_pipe\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df #[list(set(df.columns)-set(['Cabin']))]\n",
    "y = df[u'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#union.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = cross_validation.KFold(len(y), n_folds=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = cross_validation.cross_val_score(LogisticRegression(), \n",
    "                                          X=union.fit_transform(X), y=y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83798883,  0.84831461,  0.84831461,  0.83707865,  0.74719101])"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82377754064402731"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "union_pipe = make_pipeline(union, feature_selection.RFECV(LogisticRegression()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = cross_validation.cross_val_score(LogisticRegression(), \n",
    "                                          X=union_pipe.fit(X,y).transform(X), y=y, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83726068671144316"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create Dummy Variables for *Sex* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Logistic Regression and Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define the variables that we will use in our classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Transform \"Y\" into a 1-Dimensional Array for SciKit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Conduct the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Examine the coefficients to see our correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Test the Model by introducing a *Test* or *Validaton* set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Predict the class labels for the *Test* set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Predict the class probabilities for the *Test* set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Evaluate the *Test* set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Cross validate the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Check the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. What do the classification metrics tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Check the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. What does the Confusion Matrix tell us? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. What does the ROC curve tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use GridSearchCV with logistic regression to search for optimal parameters \n",
    "\n",
    "- Use the provided parameter grid. Feel free to add if you like (such as n_jobs).\n",
    "- Use 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_parameters = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-5,1,50),\n",
    "    'solver':['liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print out the best parameters and best score. Are they better than the vanilla logistic regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explain the difference between the difference between the L1 (Lasso) and L2 (Ridge) penalties on the model coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What hypothetical situations are the Ridge and Lasso penalties useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. [BONUS] Explain how the regularization strength (C) modifies the regression loss function. Why do the Ridge and Lasso penalties have their respective effects on the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.a. [BONUS] You decide that you want to minimize false positives. Use the predicted probabilities from the model to set your threshold for labeling the positive class to need at least 90% confidence. How and why does this affect your confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Gridsearch and kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform Gridsearch for the same classification problem as above, but use KNeighborsClassifier as your estimator\n",
    "\n",
    "At least have number of neighbors and weights in your parameters dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print the best parameters and score for the gridsearched kNN model. How does it compare to the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. How does the number of neighbors affect the bias-variance tradeoff of your model?\n",
    "\n",
    "#### [BONUS] Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. In what hypothetical scenario(s) might you prefer logistic regression over kNN, aside from model performance metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Fit a new kNN model with the optimal parameters found in gridsearch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Construct the confusion matrix for the optimal kNN model. Is it different from the logistic regression model? If so, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. [BONUS] Plot the ROC curves for the optimized logistic regression model and the optimized kNN model on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: [BONUS] Precision-recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Gridsearch the same parameters for logistic regression but change the scoring function to 'average_precision'\n",
    "\n",
    "`'average_precision'` will optimize parameters for area under the precision-recall curve instead of for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Examine the best parameters and score. Are they different than the logistic regression gridsearch in part 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create the confusion matrix. Is it different than when you optimized for the accuracy? If so, why would this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Plot the precision-recall curve. What does this tell us as opposed to the ROC curve?\n",
    "\n",
    "[See the sklearn plotting example here.](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: [VERY BONUS] Decision trees, ensembles, bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Gridsearch a decision tree classifier model on the data, searching for optimal depth. Create a new decision tree model with the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compare the performace of the decision tree model to the logistic regression and kNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Plot all three optimized models' ROC curves on the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use sklearn's BaggingClassifier with the base estimator your optimized decision tree model. How does the performance compare to the single decision tree classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Gridsearch the optimal n_estimators, max_samples, and max_features for the bagging classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Create a bagging classifier model with the optimal parameters and compare it's performance to the other two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
