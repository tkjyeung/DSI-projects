{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients Descent - Part 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn import datasets, linear_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate some data\n",
    "\n",
    "Using function $y = 4 + 3 x_1 + 10 x_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_thetas = [4, 3, 10] \n",
    "n_thetas = len(real_thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_data(real_thetas, size, vmin, vmax, noise_var):\n",
    "    x0=np.ones(size)\n",
    "    X = np.array([x0] + \\\n",
    "                 [np.random.uniform(vmin, vmax, size=size)\n",
    "                  for _ in range(len(real_thetas)-1)])\n",
    "\n",
    "    # add noise\n",
    "    y = np.dot(real_thetas, X) + np.random.normal(0.0, noise_var, size=size) \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = generate_data(real_thetas=real_thetas, size=1000, vmin=0, vmax=1, noise_var=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cost_function(thetas, X, y):\n",
    "    return np.mean(np.power(np.dot(X.T, thetas) - y, 2))/2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_step(thetas, alpha, X, y, momentum=1.0, momentum_factor=0.9):\n",
    "    n = float(len(X))\n",
    "    \n",
    "    # Make sure X has theta[0]\n",
    "    pred = np.dot(X.T, thetas) \n",
    "    loss = pred - y\n",
    "    gradient =  np.dot(X, loss.T) / n \n",
    "    # gradient =  np.sum(X * loss) / n \n",
    "    delta = momentum_factor*momentum + alpha * gradient\n",
    "    thetas = thetas - delta\n",
    "    \n",
    "    return thetas, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_thetas_cost(thetas, cost, delta_cost = None):\n",
    "    print \"C:{0:8.4f}\\tXs:\".format(cost),\n",
    "    for t in thetas:\n",
    "        print \"{0:8.4f}\".format(t),\n",
    "\n",
    "    if delta_cost and delta_cost > 0:\n",
    "        print \"↓\"\n",
    "    else:\n",
    "        print \"↑\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, alpha=0.0005, max_steps=1000, n_thetas=n_thetas, momentum=0.0, momentum_factor=0.9, verbose=1):\n",
    "\n",
    "    thetas = np.ones(n_thetas)\n",
    "\n",
    "    costs = [cost_function(thetas, X, y)]\n",
    "    if verbose > 0:\n",
    "        print_thetas_cost(thetas, costs[-1])\n",
    "    \n",
    "    for i in range(max_steps):\n",
    "        thetas, momentum = gradient_descent_step(thetas, alpha, X, y, momentum)\n",
    "        cost = cost_function(thetas, X, y)\n",
    "        costs.append(cost)\n",
    "        if len(costs) > 1:\n",
    "            delta_cost = costs[-2] - costs[-1]\n",
    "\n",
    "            if verbose > 0:\n",
    "                print_thetas_cost(thetas, cost, delta_cost)\n",
    "            \n",
    "            if abs(delta_cost) < 0.00001:\n",
    "                print \n",
    "                print \"Converged @\", i\n",
    "                break\n",
    "                \n",
    "    return thetas, costs[-1]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converged @ 129\n",
      "Found this:\n",
      "C:  0.5132\tXs:   4.0017   3.0214  10.0217 ↑\n",
      "Real is:\n",
      "C:  0.0000\tXs:   4.0000   3.0000  10.0000 ↑\n"
     ]
    }
   ],
   "source": [
    "thetas, cost = gradient_descent(X, y, verbose=0)\n",
    "print \"Found this:\"\n",
    "print_thetas_cost(thetas, cost)\n",
    "print \"Real is:\"\n",
    "print_thetas_cost(real_thetas, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Test another data set generated from by: $y = 10 + 4x_1 + 9x_2 - 40x_3 + 23x_4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
