{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   |True | False |   \n",
    "|---|---|---|\n",
    "|   |   |   |   \n",
    "|True | Correct!  | **Type 1 Error**  |  \n",
    "|False  | **Type 2 Error**  | Correct!  | \n",
    "\n",
    "- **True Positives**: A positive class observation (1) is correctly classified as positive by the model.\n",
    "- **False Positive**: A negative class observation (0) is incorrectly classified as positive.\n",
    "- **True Negative**: A negative class observation is correctly classified as negative.\n",
    "- **False Negative**: A positive class observation is incorrectly classified as negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load logistic regression, numpy, and cross validation train/test split functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to the Wisconsin breast cancer data. Clean it up as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_names = ['id',\n",
    "                'clump_thickness',\n",
    "                'cell_size_uniformity',\n",
    "                'cell_shape_uniformity',\n",
    "                'marginal_adhesion',\n",
    "                'single_epithelial_size',\n",
    "                'bare_nuclei',\n",
    "                'bland_chromatin',\n",
    "                'normal_nucleoli',\n",
    "                'mitoses',\n",
    "                'class']\n",
    "\n",
    "bcw = pd.read_csv('../assets/datasets/breast-cancer-wisconsin.csv',\n",
    "                 names=column_names, na_values=['?'])\n",
    "\n",
    "bcw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcw.dropna(inplace=True)\n",
    "print(bcw.shape)\n",
    "bcw.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a percentage score across the predictor columns for simplicity in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's select everything from our column_names, minus the \"class\" and \"id\" columns\n",
    "subset_mask = list(set(column_names) - set(['class', 'id']))   # difference set operation\n",
    "subset_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcw[subset_mask].sum(axis=1)/90 # axis:1 == rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcw['metrics_pct'] = bcw[subset_mask].sum(axis=1)/90.\n",
    "bcw['class'] = bcw['class'].map(lambda x: 0 if x == 2 else 1) # Here we're shifting 2 & 4 to 0 (healthy) and 1 (cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Notice our class and new metrics_pct\n",
    "bcw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Patients with cancer:', np.sum(bcw[['class']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into 66% training set and 33% testing set\n",
    ">```\n",
    ">X = metrics_pct (predictor)\n",
    ">Y = class (non-cancer:0 vs cancer:1)\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics_pct = np.array(bcw.metrics_pct.values)\n",
    "metrics_pct = metrics_pct[:, np.newaxis]\n",
    "\n",
    "# stratify keeps our classes balanced\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(metrics_pct, bcw[['class']].values, \n",
    "                                                    test_size=0.33, stratify=bcw[['class']].values,\n",
    "                                                    random_state=77)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the logistic regression on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=77)\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conmat = np.array(confusion_matrix(Y_test, Y_pred, labels=[1,0]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['has_cancer', 'is_healthy'],\n",
    "                         columns=['predicted_cancer','predicted_healthy'])\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate true positives, false positives, true negatives, and false negatives from the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TP = confusion.ix['has_cancer', 'predicted_cancer']   # row index: has_cancer column_index: predicted_cancer\n",
    "FP = confusion.ix['is_healthy', 'predicted_cancer']\n",
    "TN = confusion.ix['is_healthy', 'predicted_healthy']\n",
    "FN = confusion.ix['has_cancer', 'predicted_healthy']\n",
    "\n",
    "print(zip(['True Positives','False Positives','True Negatives','False Negatives'],\n",
    "          [TP, FP, TN, FN]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- People with cancer:  ??\n",
    "- People without cancer: ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the accuracy with the accuracy_score() function from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the accuracy is equivalent to: True Positives + True Negatives / Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print((TP + TN) / float(len(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the classification report with the classification_report() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cls_rep = classification_report(Y_test, Y_pred)\n",
    "print(cls_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the precision (for 1 vs 0) is equivalent to: True Positives / (True Positives + False Positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1 vs. 0\n",
    "print(float(TP) / (TP + FP))\n",
    "\n",
    "# 0 vs. 1\n",
    "print(float(TN) / (TN + FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the recall (for 1 vs 0) is equivalent to: True Positives / (True Positives + False Negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## How many class predictions did we \"recall\" correctly?\n",
    "# 1 vs. 0\n",
    "print(float(TP) / (TP + FN))\n",
    "\n",
    "# 0 vs. 1\n",
    "print(float(TN) / (TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the F1-score is equivalent to: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "![](https://upload.wikimedia.org/math/9/9/1/991d55cc29b4867c88c6c22d438265f9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1 vs. 0\n",
    "pos_precision = float(TP) / (TP + FP)\n",
    "pos_recall = float(TP) / (TP + FN)\n",
    "print(2. * (pos_precision * pos_recall) / (pos_precision + pos_recall))\n",
    "\n",
    "# 0 vs. 1\n",
    "neg_precision = float(TN) / (TN + FN)\n",
    "neg_recall = float(TN) / (TN + FP)\n",
    "print(2. * (neg_precision * neg_recall) / (neg_precision + neg_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
