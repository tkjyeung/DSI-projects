{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Pipeline Lab\n",
    "\n",
    "\n",
    "## 1. Data loading\n",
    "In this lab we will create pipelines for data processing on the [Titanic dataset](http://www.kaggle.com/c/titanic-gettingStarted/data).\n",
    "\n",
    "The dataset is a list of passengers. The second column of the dataset is a “label” for each person indicating whether that person survived (1) or did not survive (0). Here is the Kaggle page with more information on the dataset:\n",
    "\n",
    "You can grab the titanic data as follows:\n",
    "\n",
    "    psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "    password: gastudents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install sqlalchemy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "#import psycopg2\n",
    "#engine = create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')\n",
    "\n",
    "#df = pd.read_sql('SELECT * FROM train', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../assets/datasets/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the data using the info method:\n",
    "\n",
    "- Are there numerical features?\n",
    "- Are there categorical features?\n",
    "- Which columns have missing data?\n",
    "- Which of these are important to be filled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Age\n",
    "\n",
    "Several passengers are missing data points for age. Impute the missing values so that there are no “NaN” values for age as inputs to your model. Explore the distribution of age and decide how you are going to impute the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Age.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b: Age Transformer\n",
    "\n",
    "Create a custom transformer that imputes the age values. Depending on how you have decided to impute missing values, this could involve:\n",
    "\n",
    "- Selecting one or more columns\n",
    "- Filling the NAs using Imputer or a custom strategy\n",
    "- Scaling the Age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return pd.DataFrame(X[self.columns])\n",
    "        else:\n",
    "            raise TypeError(\"This transformer only works with Pandas Dataframes\")\n",
    "    \n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "    \n",
    "cs = ColumnSelector('Age')\n",
    "\n",
    "cs.transform(df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_pipe = make_pipeline(ColumnSelector('Age'),\n",
    "                         Imputer(),\n",
    "                         StandardScaler())\n",
    "\n",
    "age_pipe.fit_transform(df)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Categorical Variables\n",
    "\n",
    "`Embarked` and `Pclass` are categorical variables. Use pandas get_dummies function to create dummy columns corresponding to the values.\n",
    "\n",
    "`Embarked` has 2 missing values. Fill them with the most common port of embarkment.\n",
    "\n",
    "Feel free to create a GetDummiesTransformer that wraps around the get_dummies function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.Embarked = df.Embarked.fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(pd.DataFrame(df['Embarked'].head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GetDummiesTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return pd.get_dummies(X[self.columns], columns = self.columns)\n",
    "        else:\n",
    "            raise TypeError(\"This transformer only works with Pandas Dataframes\")\n",
    "    \n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "    \n",
    "gdt = GetDummiesTransformer(['Embarked'])\n",
    "gdt.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_hot_pipe = GetDummiesTransformer(['Pclass', 'Embarked'])\n",
    "\n",
    "one_hot_pipe.fit_transform(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Boolean Columns\n",
    "\n",
    "The `Sex` column only contains 2 values: `male` and `female`. Build a custom transformers that is initialized with one of the values and returns a boolean column with values of `True` when that value is found and `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrueFalseTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, flag):\n",
    "        self.flag = flag\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        return X == self.flag\n",
    "\n",
    "    def fit(self, X, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_pipe = make_pipeline(ColumnSelector('Sex'),\n",
    "                            TrueFalseTransformer('male'))\n",
    "\n",
    "gender_pipe.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fare\n",
    "\n",
    "The `Fare` attribute can be scaled using one of the scalers from the preprocessing module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fare_pipe = make_pipeline(ColumnSelector('Fare'),\n",
    "                          StandardScaler())\n",
    "\n",
    "fare_pipe.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Union\n",
    "\n",
    "Use the `make_union` function from the `sklearn.pipeline` modeule to combine all the pipes you have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "union = make_union(age_pipe,\n",
    "                   one_hot_pipe,\n",
    "                   gender_pipe,\n",
    "                   fare_pipe)\n",
    "\n",
    "# union.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Embarked']]\n",
    "y = df[u'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "union.fit(X)\n",
    "# X = union.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The union you have created is a complete pre-processing pipeline that takes the original titanic dataset and extracts a bunch of features out of it. The last step of this process is to persist the `union` object to disk, so that it can be used again later. The following lines achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "import gzip\n",
    "\n",
    "\n",
    "with gzip.open('../../assets/datasets/union.dill.gz', 'w') as fout:\n",
    "    dill.dump(union, fout)\n",
    "    dill.dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import dill\n",
    "# import gzip\n",
    "\n",
    "# with gzip.open('../../assets/datasets/union.dill.gz', 'r') as fi:\n",
    "#     union = dill.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5924806 ,  0.        ,  0.        , ...,  1.        ,\n",
       "         1.        , -0.50244517],\n",
       "       [ 0.63878901,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.78684529],\n",
       "       [-0.2846632 ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        , -0.48885426],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        , -0.17626324],\n",
       "       [-0.2846632 ,  1.        ,  0.        , ...,  0.        ,\n",
       "         1.        , -0.04438104],\n",
       "       [ 0.17706291,  0.        ,  0.        , ...,  0.        ,\n",
       "         1.        , -0.49237783]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Can you think of a way to engineer an additional boolean feature that keeps track whethere the person is travelling alone or with family?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df['Family'] = (df['Parch'] > 0 ) & (df['SibSp'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
