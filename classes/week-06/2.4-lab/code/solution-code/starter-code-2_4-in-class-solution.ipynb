{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Ensembles Lab\n",
    "\n",
    "In this lab we will compare the performance of a simple Decision Tree classifier with a Bagging classifier. We will do that on few datasets, starting from the ones offered by Scikit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Breast Cancer Dataset\n",
    "We will start our comparison on the breast cancer dataset.\n",
    "You can load it directly from scikit-learn using the `load_breast_cancer` function.\n",
    "\n",
    "### 1.a Simple comparison\n",
    "1. Load the data and create X and y\n",
    "- Initialize a Decision Tree Classifier and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds\n",
    "- Wrap a Bagging Classifier around the Decision Tree Classifier and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. \n",
    "- Which score is better? Are the score significantly different? How can you judge that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_names', 'data', 'target', 'DESCR', 'feature_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33            184.6      2019.0            0.1622   \n",
       "1          23.41            158.8      1956.0            0.1238   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree, metrics, ensemble, cross_validation, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = cross_validation.KFold(len(y), n_folds=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93859649  0.95614035  0.93859649  0.96491228  0.92920354]\n",
      "0.945489830772\n"
     ]
    }
   ],
   "source": [
    "results = cross_validation.cross_val_score(estimator=estimator, X=X, y=y, cv=cv)\n",
    "print results\n",
    "print np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_estimator = ensemble.BaggingClassifier(base_estimator=tree.DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96491228  0.95614035  0.92982456  0.95614035  0.95575221]\n",
      "0.95255395125\n"
     ]
    }
   ],
   "source": [
    "results = cross_validation.cross_val_score(estimator=bag_estimator, X=X, y=y, cv=cv)\n",
    "print results\n",
    "print np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96491228  0.93859649  0.92982456  0.97368421  0.94690265]\n",
      "0.950784039745\n"
     ]
    }
   ],
   "source": [
    "results = cross_validation.cross_val_score(estimator=linear_model.LogisticRegression(), X=X, y=y, cv=cv)\n",
    "print results\n",
    "print np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96491228  0.92105263  0.92982456  0.96491228  0.9380531 ]\n",
      "0.943750970346\n"
     ]
    }
   ],
   "source": [
    "bag_estimator = ensemble.BaggingClassifier(base_estimator=linear_model.LogisticRegression())\n",
    "results = cross_validation.cross_val_score(estimator=bag_estimator, X=X, y=y, cv=cv)\n",
    "print results\n",
    "print np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b Scaled pipelines\n",
    "As you may have noticed the features are not normalized. Do the score improve with normalization?\n",
    "By now you should be very familiar with pipelines and scaling, so:\n",
    "\n",
    "1. Create 2 pipelines, with a scaling preprocessing step and then either a decision tree or a bagging decision tree.\n",
    "- Which score is better? Are the score significantly different? How can you judge that?\n",
    "- Are the scores different from the non-scaled data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import pipeline, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_decision_tree = pipeline.make_pipeline(preprocessing.StandardScaler(),\n",
    "                                            tree.DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95614035  0.96491228  0.9122807   0.96491228  0.92035398]\n",
      "0.943719919267\n"
     ]
    }
   ],
   "source": [
    "results = cross_validation.cross_val_score(estimator=pipe_decision_tree, X=X, y=y, cv=cv)\n",
    "print results\n",
    "print np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_estimator = ensemble.BaggingClassifier(base_estimator=tree.DecisionTreeClassifier())\n",
    "pipe_decision_bag = pipeline.make_pipeline(preprocessing.StandardScaler(),\n",
    "                                            bag_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97368421  0.97368421  0.92982456  0.96491228  0.94690265]\n",
      "0.957801583605\n"
     ]
    }
   ],
   "source": [
    "results = cross_validation.cross_val_score(estimator=pipe_decision_bag, X=X, y=y, cv=cv)\n",
    "print results\n",
    "print np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_decision_lr = pipeline.make_pipeline(preprocessing.StandardScaler(),\n",
    "                                          linear_model.LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99122807  0.98245614  0.99122807  0.97368421  0.96460177]\n",
      "0.980639652228\n"
     ]
    }
   ],
   "source": [
    "results = cross_validation.cross_val_score(estimator=pipe_decision_lr, X=X, y=y, cv=cv)\n",
    "print results\n",
    "print np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_estimator = ensemble.BaggingClassifier(base_estimator=linear_model.LogisticRegression())\n",
    "pipe_decision_tree = pipeline.make_pipeline(preprocessing.StandardScaler(),\n",
    "                                            bag_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99122807  0.98245614  0.99122807  0.97368421  0.96460177]\n",
      "0.980639652228\n"
     ]
    }
   ],
   "source": [
    "results = cross_validation.cross_val_score(estimator=pipe_decision_lr, X=X, y=y, cv=cv)\n",
    "print results\n",
    "print np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c Grid Search\n",
    "\n",
    "Grid search is a great way to improve the performance of a classifier. Let's explore the parameter space of both models and see if we can improve their performance.\n",
    "\n",
    "1. Initialize a GridSearchCV with 5-fold cross validation for the Decision Tree Classifier\n",
    "- search for few values of the parameters in order to improve the score of the classifier\n",
    "- Use the whole X, y dataset for your test\n",
    "- Check the best\\_score\\_ once you've trained it. Is it better than before?\n",
    "- How does the score of the Grid-searched DT compare with the score of the Bagging DT?\n",
    "- Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Classifier\n",
    "- Repeat the search\n",
    "    - Note that you'll have to change parameter names for the base_estimator\n",
    "    - Note that there are also additional parameters to change\n",
    "    - Note that you may end up with a grid space to large to search in a short time\n",
    "    - Make use of the n_jobs parameter to speed up your grid search\n",
    "- Does the score improve for the Grid-searched Bagging Classifier?\n",
    "- Which score is better? Are the score significantly different? How can you judge that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_decision_tree = pipeline.make_pipeline(preprocessing.StandardScaler(),\n",
    "                                            tree.DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('decisiontreeclassifier', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decision_tree_parameters = {\n",
    "    'decisiontreeclassifier__max_depth': [3, 5, 7],\n",
    "    'decisiontreeclassifier__max_features': [1, 5, 10, 0.1, 0.3, 0.5, 0.9, \"sqrt\", \"log2\", None],\n",
    "    'decisiontreeclassifier__criterion': ['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = grid_search.GridSearchCV(estimator=pipe_decision_tree, param_grid=decision_tree_parameters, cv=cv, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=569, n_folds=5, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('decisiontreeclassifier', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'decisiontreeclassifier__max_depth': [3, 5, 7], 'decisiontreeclassifier__criterion': ['gini', 'entropy'], 'decisiontreeclassifier__max_features': [1, 5, 10, 0.1, 0.3, 0.5, 0.9, 'sqrt', 'log2', None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('decisiontreeclassifier', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=10, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_estimator = ensemble.BaggingClassifier(base_estimator=tree.DecisionTreeClassifier())\n",
    "pipe_decision_bag = pipeline.make_pipeline(preprocessing.StandardScaler(),\n",
    "                                            bag_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('baggingclassifier', BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            ...estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_decision_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baggingclassifier',\n",
       " 'baggingclassifier__base_estimator',\n",
       " 'baggingclassifier__base_estimator__class_weight',\n",
       " 'baggingclassifier__base_estimator__criterion',\n",
       " 'baggingclassifier__base_estimator__max_depth',\n",
       " 'baggingclassifier__base_estimator__max_features',\n",
       " 'baggingclassifier__base_estimator__max_leaf_nodes',\n",
       " 'baggingclassifier__base_estimator__min_samples_leaf',\n",
       " 'baggingclassifier__base_estimator__min_samples_split',\n",
       " 'baggingclassifier__base_estimator__min_weight_fraction_leaf',\n",
       " 'baggingclassifier__base_estimator__presort',\n",
       " 'baggingclassifier__base_estimator__random_state',\n",
       " 'baggingclassifier__base_estimator__splitter',\n",
       " 'baggingclassifier__bootstrap',\n",
       " 'baggingclassifier__bootstrap_features',\n",
       " 'baggingclassifier__max_features',\n",
       " 'baggingclassifier__max_samples',\n",
       " 'baggingclassifier__n_estimators',\n",
       " 'baggingclassifier__n_jobs',\n",
       " 'baggingclassifier__oob_score',\n",
       " 'baggingclassifier__random_state',\n",
       " 'baggingclassifier__verbose',\n",
       " 'baggingclassifier__warm_start',\n",
       " 'standardscaler',\n",
       " 'standardscaler__copy',\n",
       " 'standardscaler__with_mean',\n",
       " 'standardscaler__with_std',\n",
       " 'steps']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pipe_decision_bag.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decision_tree_bag_parameters = {    \n",
    "    'baggingclassifier__base_estimator__max_depth': [3, 5, 7],\n",
    "    'baggingclassifier__base_estimator__max_features': [1, 5, 10, 0.1, 0.3, 0.5, 0.9, \"sqrt\", \"log2\", None],\n",
    "    'baggingclassifier__base_estimator__criterion': ['gini'],\n",
    "    'baggingclassifier__bootstrap': [False, True],\n",
    "    'baggingclassifier__n_estimators': [5, 10, 100, 200]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs = grid_search.GridSearchCV(estimator=pipe_decision_bag, param_grid=decision_tree_bag_parameters, \n",
    "                              cv=cv, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 242 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=-1)]: Done 492 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 842 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=569, n_folds=5, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('baggingclassifier', BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            ...estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'baggingclassifier__bootstrap': [False, True], 'baggingclassifier__base_estimator__max_depth': [3, 5, 7], 'baggingclassifier__base_estimator__criterion': ['gini'], 'baggingclassifier__n_estimators': [5, 10, 100, 200], 'baggingclassifier__base_estimator__max_features': [1, 5, 10, 0.1, 0.3, 0.5, 0.9, 'sqrt', 'log2', None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baggingclassifier__base_estimator__criterion': 'gini',\n",
       " 'baggingclassifier__base_estimator__max_depth': 7,\n",
       " 'baggingclassifier__base_estimator__max_features': 0.3,\n",
       " 'baggingclassifier__bootstrap': False,\n",
       " 'baggingclassifier__n_estimators': 10}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decision_tree_bag_parameters = {    \n",
    "    #'baggingclassifier__base_estimator__max_depth': [1, 2, 7, 10, 20, None],\n",
    "    #'baggingclassifier__base_estimator__max_features': [1, \"sqrt\", None],\n",
    "    #'baggingclassifier__n_estimators': [10, 100, 200, 400]\n",
    "    'baggingclassifier__base_estimator__max_depth': [10],\n",
    "    'baggingclassifier__base_estimator__max_features': [\"sqrt\"],\n",
    "    'baggingclassifier__n_estimators': [600, 1000, 2000]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = grid_search.GridSearchCV(estimator=pipe_decision_bag, param_grid=decision_tree_bag_parameters, \n",
    "                              cv=cv, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   25.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=569, n_folds=5, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('baggingclassifier', BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            ...estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'baggingclassifier__base_estimator__max_depth': [10], 'baggingclassifier__n_estimators': [600, 1000, 2000], 'baggingclassifier__base_estimator__max_features': ['sqrt']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baggingclassifier__base_estimator__max_depth': 10,\n",
       " 'baggingclassifier__base_estimator__max_features': 'sqrt',\n",
       " 'baggingclassifier__n_estimators': 1000}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96309314586994732"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baggingclassifier__base_estimator__max_depth': 10,\n",
       " 'baggingclassifier__base_estimator__max_features': 'sqrt',\n",
       " 'baggingclassifier__n_estimators': 1000}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96309314586994732"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now with more trees!\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Diabetes and Regression\n",
    "\n",
    "Scikit Learn has a dataset of diabetic patients obtained from this study:\n",
    "\n",
    "http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
    "http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf\n",
    "\n",
    "442 diabetes patients were measured on 10 baseline variables: age, sex, body mass index, average blood pressure, and six blood serum measurements.\n",
    "\n",
    "The target is a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "Repeat the above comparison between a DecisionTreeRegressor and a Bagging version of the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a Simple comparison\n",
    "1. Load the data and create X and y\n",
    "- Initialize a Decision Tree Regressor and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. Which score will you use?\n",
    "- Wrap a Bagging Regressor around the Decision Tree Regressor and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. \n",
    "- Which score is better? Are the score significantly different? How can you judge that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes()\n",
    "X = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "def do_cross_val(model):\n",
    "    scores = cross_validation.cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring='r2')\n",
    "    return scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.1381552312490964, 0.099290837989405342)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = tree.DecisionTreeRegressor()\n",
    "do_cross_val(dtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38933386026646832, 0.057585796826444401)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdtr = ensemble.BaggingRegressor(DecisionTreeRegressor())\n",
    "do_cross_val(bdtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b Grid Search\n",
    "\n",
    "Repeat Grid search as above:\n",
    "\n",
    "1. Initialize a GridSearchCV with 5-fold cross validation for the Decision Tree Regressor\n",
    "- Search for few values of the parameters in order to improve the score of the regressor\n",
    "- Use the whole X, y dataset for your test\n",
    "- Check the best\\_score\\_ once you've trained it. Is it better than before?\n",
    "- How does the score of the Grid-searched DT compare with the score of the Bagging DT?\n",
    "- Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Regressor\n",
    "- Repeat the search\n",
    "    - Note that you'll have to change parameter names for the base_estimator\n",
    "    - Note that there are also additional parameters to change\n",
    "    - Note that you may end up with a grid space to large to search in a short time\n",
    "    - Make use of the n_jobs parameter to speed up your grid search\n",
    "- Does the score improve for the Grid-searched Bagging Regressor?\n",
    "- Which score is better? Are the score significantly different? How can you judge that?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\"splitter\": ['best', 'random'],\n",
    "          \"max_depth\": [3,5,10,20],\n",
    "          \"max_features\": [None, \"auto\"],\n",
    "          \"min_samples_leaf\": [1, 3, 5, 7, 10],\n",
    "          \"min_samples_split\": [2, 5, 7]\n",
    "         }\n",
    "    \n",
    "\n",
    "gsdtr = grid_search.GridSearchCV(dtr, params, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [None, 'auto'], 'splitter': ['best', 'random'], 'min_samples_split': [2, 5, 7], 'max_depth': [3, 5, 10, 20], 'min_samples_leaf': [1, 3, 5, 7, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdtr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 5,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdtr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38043699046389667"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdtr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\"base_estimator__splitter\": ['best', 'random'],\n",
    "          \"base_estimator__max_depth\": [3,5,10,20],\n",
    "          \"base_estimator__max_features\": [None, \"auto\"],\n",
    "          \"base_estimator__min_samples_leaf\": [1, 3, 5, 7, 10],\n",
    "          \"base_estimator__min_samples_split\": [2, 5, 7],\n",
    "          'bootstrap_features': [False, True],\n",
    "          'max_features': [0.5, 0.7, 1.0],\n",
    "          'max_samples': [0.5, 0.7, 1.0],\n",
    "          'n_estimators': [2, 5, 10, 20],\n",
    "         }\n",
    "    \n",
    "\n",
    "gsbdtr = grid_search.GridSearchCV(bdtr, params, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [2, 5, 10, 20], 'max_samples': [0.5, 0.7, 1.0], 'base_estimator__min_samples_split': [2, 5, 7], 'base_estimator__max_depth': [3, 5, 10, 20], 'bootstrap_features': [False, True], 'base_estimator__splitter': ['best', 'random'], 'max_features': [0.5, 0.7, 1.0], 'base_estimator__min_samples_leaf': [1, 3, 5, 7, 10], 'base_estimator__max_features': [None, 'auto']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbdtr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__max_depth': 20,\n",
       " 'base_estimator__max_features': 'auto',\n",
       " 'base_estimator__min_samples_leaf': 5,\n",
       " 'base_estimator__min_samples_split': 7,\n",
       " 'base_estimator__splitter': 'random',\n",
       " 'bootstrap_features': False,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 0.7,\n",
       " 'n_estimators': 20}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbdtr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48394816295048837"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbdtr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Project 6 data\n",
    "\n",
    "Repeat the analysis for the Project 6 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
